{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Model and Prediction\n",
    "\n",
    "Model selection and tuning of the model\n",
    "\n",
    "## Data files needed to run this notebook:\n",
    "- X_train.pkl.gz\n",
    "- X_test.pkl.gz\n",
    "- y_test_.pkl.gz\n",
    "- y_train.pkl.gz\n",
    "\n",
    "all the results from notebook 04\n",
    "\n",
    "## Settings:\n",
    "- set `COLAB = True` if you run this on Colab. Data can be placed in the root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from collections import Counter\n",
    "import re\n",
    "from numpy import log, mean, matmul\n",
    "\n",
    "\n",
    "required = {'spacy', 'scikit-learn', 'numpy', \n",
    "            'pandas', 'torch', 'matplotlib',\n",
    "            'transformers', 'allennlp==0.9.0'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SciKit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Spacy\n",
    "from spacy.lang.en import English\n",
    "en = English()\n",
    "\n",
    "# !python -m spacy download en_core_web_md # includes GloVe Vectors\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en\n",
    "\n",
    "# import en_core_web_sm\n",
    "# import en_core_web_md\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File managment\n",
    "import os\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_DATA = False # read save data or regenerate data\n",
    "SAVE_DATA = False # overwrite generated data? \n",
    "\n",
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  # Google Colab\n",
    "  path = \"./\"\n",
    "  device = torch.device(\"cuda:0\") # use GPU, change \n",
    "else:\n",
    "  # Laptop\n",
    "  path = \"./data/\"\n",
    "  device = torch.device(\"cpu\")\n",
    "#   !pip install ipywidgets\n",
    "#   !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total = pd.read_pickle(f'{path}df_total_cleaned.pkl.gz')\n",
    "\n",
    "X_train = pd.read_pickle(f'{path}X_train.pkl.gz')\n",
    "y_train = pd.read_pickle(f'{path}y_train.pkl.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\"SName\", \"Lyric\", \"Artist\"]\n",
    "genres = list(pd.DataFrame(y_train)[\"Genre\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19167     Hip Hop\n",
       "88089     Hip Hop\n",
       "41285     Hip Hop\n",
       "12664        Rock\n",
       "52249     Hip Hop\n",
       "           ...   \n",
       "127879      Metal\n",
       "80491        Rock\n",
       "66750        Rock\n",
       "133337      Metal\n",
       "99994        Rock\n",
       "Name: Genre, Length: 8400, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19167</th>\n",
       "      <td>0.001492</td>\n",
       "      <td>-0.273682</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>-0.246460</td>\n",
       "      <td>-0.050476</td>\n",
       "      <td>-0.072327</td>\n",
       "      <td>0.447510</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>-0.255859</td>\n",
       "      <td>-0.431396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408203</td>\n",
       "      <td>-1.025391</td>\n",
       "      <td>-0.107178</td>\n",
       "      <td>-0.021561</td>\n",
       "      <td>0.352051</td>\n",
       "      <td>0.488770</td>\n",
       "      <td>-0.528320</td>\n",
       "      <td>-0.062469</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.423340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88089</th>\n",
       "      <td>0.037231</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>0.496826</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>-0.322998</td>\n",
       "      <td>-0.077271</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>-0.482910</td>\n",
       "      <td>-0.359619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>-0.338623</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.612305</td>\n",
       "      <td>0.417236</td>\n",
       "      <td>-0.303955</td>\n",
       "      <td>-0.520508</td>\n",
       "      <td>0.493164</td>\n",
       "      <td>0.340820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41285</th>\n",
       "      <td>-0.041718</td>\n",
       "      <td>-0.246704</td>\n",
       "      <td>-0.162720</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>-0.043579</td>\n",
       "      <td>-0.229004</td>\n",
       "      <td>0.499023</td>\n",
       "      <td>0.824219</td>\n",
       "      <td>0.036102</td>\n",
       "      <td>-0.441650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738770</td>\n",
       "      <td>-0.558594</td>\n",
       "      <td>-0.090698</td>\n",
       "      <td>-0.180176</td>\n",
       "      <td>0.313232</td>\n",
       "      <td>0.296143</td>\n",
       "      <td>-0.604004</td>\n",
       "      <td>-0.382080</td>\n",
       "      <td>0.578613</td>\n",
       "      <td>0.207520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12664</th>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.143311</td>\n",
       "      <td>-0.226196</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.749023</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>0.955078</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>-0.119263</td>\n",
       "      <td>-0.517090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>-0.275879</td>\n",
       "      <td>-0.046143</td>\n",
       "      <td>-0.173706</td>\n",
       "      <td>0.242676</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>-0.583008</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.259033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52249</th>\n",
       "      <td>0.061066</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.814453</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>-0.344238</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.367432</td>\n",
       "      <td>-0.025284</td>\n",
       "      <td>-0.302490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408936</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>-0.401855</td>\n",
       "      <td>0.095398</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.496582</td>\n",
       "      <td>-0.437256</td>\n",
       "      <td>0.364258</td>\n",
       "      <td>0.228882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127879</th>\n",
       "      <td>-0.169678</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>-0.042542</td>\n",
       "      <td>-0.390625</td>\n",
       "      <td>-0.249268</td>\n",
       "      <td>0.797852</td>\n",
       "      <td>0.419189</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>-0.881348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206543</td>\n",
       "      <td>-0.823730</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>-0.105835</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.190796</td>\n",
       "      <td>-0.207031</td>\n",
       "      <td>-0.497314</td>\n",
       "      <td>0.233032</td>\n",
       "      <td>-0.636230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80491</th>\n",
       "      <td>-0.017868</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.343506</td>\n",
       "      <td>-0.726562</td>\n",
       "      <td>-0.599609</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.419678</td>\n",
       "      <td>0.360107</td>\n",
       "      <td>0.517578</td>\n",
       "      <td>-0.833008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453857</td>\n",
       "      <td>-0.279053</td>\n",
       "      <td>-0.021866</td>\n",
       "      <td>-0.483154</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.191284</td>\n",
       "      <td>-0.330811</td>\n",
       "      <td>-0.092896</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>0.769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66750</th>\n",
       "      <td>-0.179810</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>-0.214478</td>\n",
       "      <td>0.788574</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>-0.184082</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.797852</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>-0.049011</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.599609</td>\n",
       "      <td>-0.137939</td>\n",
       "      <td>-0.099487</td>\n",
       "      <td>-0.040466</td>\n",
       "      <td>0.257568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133337</th>\n",
       "      <td>-0.553223</td>\n",
       "      <td>0.139282</td>\n",
       "      <td>0.312256</td>\n",
       "      <td>0.208862</td>\n",
       "      <td>-0.581055</td>\n",
       "      <td>-0.247070</td>\n",
       "      <td>0.706543</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.349121</td>\n",
       "      <td>-0.726074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300049</td>\n",
       "      <td>-0.753906</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>-0.461670</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>-0.375977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>-0.023071</td>\n",
       "      <td>0.130493</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.077026</td>\n",
       "      <td>-0.200073</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.388184</td>\n",
       "      <td>0.555176</td>\n",
       "      <td>-0.610840</td>\n",
       "      <td>-0.278076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139771</td>\n",
       "      <td>-0.655762</td>\n",
       "      <td>-0.319092</td>\n",
       "      <td>-0.176147</td>\n",
       "      <td>0.576660</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>-0.161743</td>\n",
       "      <td>-0.162109</td>\n",
       "      <td>0.387939</td>\n",
       "      <td>0.464111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "19167   0.001492 -0.273682  0.150513 -0.246460 -0.050476 -0.072327  0.447510   \n",
       "88089   0.037231  0.150635  0.496826  0.196777 -0.322998 -0.077271  0.991211   \n",
       "41285  -0.041718 -0.246704 -0.162720  0.137085 -0.043579 -0.229004  0.499023   \n",
       "12664  -0.325684  0.143311 -0.226196 -0.002642 -0.749023  0.127930  0.955078   \n",
       "52249   0.061066  0.076416  0.814453 -0.269531 -0.344238  0.150757  0.812500   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "127879 -0.169678  0.041229  0.236816 -0.042542 -0.390625 -0.249268  0.797852   \n",
       "80491  -0.017868  0.076111  0.343506 -0.726562 -0.599609  0.000035  0.419678   \n",
       "66750  -0.179810 -0.208984 -0.071289  0.151611 -0.094727 -0.214478  0.788574   \n",
       "133337 -0.553223  0.139282  0.312256  0.208862 -0.581055 -0.247070  0.706543   \n",
       "99994  -0.023071  0.130493  0.133423  0.077026 -0.200073  0.148804  0.388184   \n",
       "\n",
       "             7         8         9    ...       758       759       760  \\\n",
       "19167   0.275391 -0.255859 -0.431396  ...  0.408203 -1.025391 -0.107178   \n",
       "88089   0.152954 -0.482910 -0.359619  ...  0.160156 -0.338623  0.003363   \n",
       "41285   0.824219  0.036102 -0.441650  ...  0.738770 -0.558594 -0.090698   \n",
       "12664   0.399902 -0.119263 -0.517090  ...  0.154175 -0.275879 -0.046143   \n",
       "52249   0.367432 -0.025284 -0.302490  ... -0.408936 -0.527344 -0.401855   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "127879  0.419189 -0.269531 -0.881348  ... -0.206543 -0.823730 -0.051056   \n",
       "80491   0.360107  0.517578 -0.833008  ...  0.453857 -0.279053 -0.021866   \n",
       "66750   0.704102 -0.184082 -0.365723  ...  0.017578 -0.797852  0.142456   \n",
       "133337  0.520508  0.349121 -0.726074  ... -0.300049 -0.753906 -0.207153   \n",
       "99994   0.555176 -0.610840 -0.278076  ...  0.139771 -0.655762 -0.319092   \n",
       "\n",
       "             761       762       763       764       765       766       767  \n",
       "19167  -0.021561  0.352051  0.488770 -0.528320 -0.062469  0.002211  0.423340  \n",
       "88089   0.037933  0.612305  0.417236 -0.303955 -0.520508  0.493164  0.340820  \n",
       "41285  -0.180176  0.313232  0.296143 -0.604004 -0.382080  0.578613  0.207520  \n",
       "12664  -0.173706  0.242676  0.716797 -0.252197 -0.583008  0.321533  0.259033  \n",
       "52249   0.095398  0.742676  0.281250 -0.496582 -0.437256  0.364258  0.228882  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "127879 -0.105835  0.450439  0.190796 -0.207031 -0.497314  0.233032 -0.636230  \n",
       "80491  -0.483154  0.136719  0.191284 -0.330811 -0.092896  0.070190  0.769043  \n",
       "66750  -0.049011  0.182617  0.599609 -0.137939 -0.099487 -0.040466  0.257568  \n",
       "133337 -0.024521  0.374512  0.519043  0.003078 -0.461670  0.013908 -0.375977  \n",
       "99994  -0.176147  0.576660  0.502441 -0.161743 -0.162109  0.387939  0.464111  \n",
       "\n",
       "[8400 rows x 768 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "tmp = X_train.drop(text_cols,axis=1)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, X_val_set, y_train_set, y_val_set = train_test_split(tmp, y_train, test_size=test_size, random_state=0, shuffle = True, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_SVC(x,y,x_val, y_val):\n",
    "  model = LinearSVC(max_iter=2000)\n",
    "  model.fit(x, y)\n",
    "  val_preds = model.predict(x_val)\n",
    "  acc = accuracy_score(y_val, val_preds)\n",
    "  print(f\"Accuracy: {round(acc,2)}\")\n",
    "  return (acc, model, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikbuunk/opt/anaconda3/envs/NLP/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "(acc, model, predictions) = train_SVC(X_train_set, y_train_set, X_val_set, y_val_set)\n",
    "\n",
    "# running rock,hiphop, metal: -> 92%\n",
    "# running pop,hiphop, metal: -> 85%\n",
    "# running 4 genres -> 75%\n",
    "# running pop, rock, hiphop _> 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusiont matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confustion_matrix(model, y_val_set, predictions):\n",
    "  cm = confusion_matrix(y_val_set, predictions)\n",
    "  df = pd.DataFrame(cm, columns = model.classes_, index= model.classes_)\n",
    "  print(df)\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Hip Hop  Metal  Rock\n",
      "Hip Hop      747      0    93\n",
      "Metal          0    840     0\n",
      "Rock          99      4   737\n"
     ]
    }
   ],
   "source": [
    "print_confustion_matrix(model, y_val_set, predictions)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_classifications(X_train, y, predictions, genres):\n",
    "  print(\"Truth - predicted\")\n",
    "  predictions_df = pd.DataFrame(predictions, columns = [\"Genre_Predicted\"])\n",
    "  truth_df = pd.DataFrame(y)\n",
    "  truth_df.columns = [\"Genre_Truth\"]\n",
    "  combined_df = pd.concat([truth_df.reset_index(drop=True), predictions_df.reset_index(drop=True)], axis=1)\n",
    "  for i in genres:\n",
    "    for j in genres:\n",
    "      if i!=j:\n",
    "        idx = combined_df.query(f\"Genre_Truth =='{i}' != Genre_Predicted=='{j}'\").index\n",
    "        if len(idx)>0:\n",
    "          print(\"------------------------------\")\n",
    "          print(f\"{i} - {j}\")\n",
    "          print(\"------------------------------\")\n",
    "          print(X_train.iloc[idx][\"Lyric\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth - predicted\n",
      "------------------------------\n",
      "Hip Hop - Rock\n",
      "------------------------------\n",
      "6121      previously on ashanti \"always there when you c...\n",
      "19946     Before I get started. polo this beat is retart...\n",
      "126819    Patrz   w siebie i widz   coraz mniej Powoli p...\n",
      "33512     Fatjoe: TS. Thalía: Hey baby. Fatjoe: Yeah. Th...\n",
      "126051    I felt the ground start to shake  Oh God  oh G...\n",
      "                                ...                        \n",
      "30991     Its 2002, everything was totally new. We were ...\n",
      "21676     It's time to make a difference. I know he's ba...\n",
      "112568    Cross me once more fool me cross me twice and ...\n",
      "6192       why dont you take me tonight. take me away wh...\n",
      "66616     she said that she'd take it off right here. ta...\n",
      "Name: Lyric, Length: 93, dtype: object\n",
      "------------------------------\n",
      "Rock - Hip Hop\n",
      "------------------------------\n",
      "26589     I didn't hear you leave,. I wonder how am I st...\n",
      "59383     Your breath is sweet. Your eyes are like two j...\n",
      "49296     Oo, I'm cryin', tears are fallin' down.. I'm c...\n",
      "57279     Let Me Hump You. Let Me Hump You. Let Me Hump ...\n",
      "109134    . I-I-I I Can Make Your Bed Rock. I-I-I I Can ...\n",
      "                                ...                        \n",
      "47072     Hung up here on a web of comfort.. Taking off ...\n",
      "51187     I watched you walking. Late in the day. Where ...\n",
      "95004     I build a house. For your bones. I build a hou...\n",
      "41502     We are all living the same way, the same way. ...\n",
      "65225     Tulisa:. Ha Ha Ha Ha. Dappy:. N-Dubz N-Dubz. N...\n",
      "Name: Lyric, Length: 99, dtype: object\n",
      "------------------------------\n",
      "Rock - Metal\n",
      "------------------------------\n",
      "61016     Willing and waitng.... But it's all up to you....\n",
      "103961    He breaks me down. He builds me up. He fills m...\n",
      "122080    When I get to the bottom I go back to the top ...\n",
      "142066    Forever seems so far  Forever seems so cold  F...\n",
      "Name: Lyric, dtype: object\n"
     ]
    }
   ],
   "source": [
    " \n",
    "wrong_classifications(X_train, y_val_set,predictions  , genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hip Hop       0.88      0.89      0.89       840\n",
      "        Rock       1.00      1.00      1.00       840\n",
      "       Metal       0.89      0.88      0.88       840\n",
      "\n",
      "    accuracy                           0.92      2520\n",
      "   macro avg       0.92      0.92      0.92      2520\n",
      "weighted avg       0.92      0.92      0.92      2520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val_set, predictions, target_names=genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different kernels and values of hyper parameters to see if we can improve the score\n",
    "# this method uses cross validation so we could use the whole data set (we do ot so we can use the val to get the test score of the fitted model, with the parameters. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 38s, sys: 1.36 s, total: 3min 39s\n",
      "Wall time: 3min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10],\n",
       "                         'kernel': ('linear', 'rbf', 'poly', 'sigmoid')})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train_set, y_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'C': 1, 'kernel': 'linear'}, 0.6551020408163264),\n",
       " ({'C': 1, 'kernel': 'rbf'}, 0.6914965986394558),\n",
       " ({'C': 1, 'kernel': 'poly'}, 0.6954081632653061),\n",
       " ({'C': 1, 'kernel': 'sigmoid'}, 0.6741496598639456),\n",
       " ({'C': 10, 'kernel': 'linear'}, 0.6341836734693878),\n",
       " ({'C': 10, 'kernel': 'rbf'}, 0.6952380952380952),\n",
       " ({'C': 10, 'kernel': 'poly'}, 0.6948979591836735),\n",
       " ({'C': 10, 'kernel': 'sigmoid'}, 0.6066326530612245)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(clf.cv_results_['params'], clf.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.877298</td>\n",
       "      <td>0.402755</td>\n",
       "      <td>3.374521</td>\n",
       "      <td>0.407636</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.677721</td>\n",
       "      <td>0.643707</td>\n",
       "      <td>0.643707</td>\n",
       "      <td>0.657313</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.655102</td>\n",
       "      <td>0.012493</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.557154</td>\n",
       "      <td>0.286680</td>\n",
       "      <td>4.539178</td>\n",
       "      <td>0.157519</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.703231</td>\n",
       "      <td>0.671769</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.697279</td>\n",
       "      <td>0.682823</td>\n",
       "      <td>0.691497</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.346417</td>\n",
       "      <td>0.287686</td>\n",
       "      <td>4.132863</td>\n",
       "      <td>0.193988</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.679422</td>\n",
       "      <td>0.701531</td>\n",
       "      <td>0.698980</td>\n",
       "      <td>0.687925</td>\n",
       "      <td>0.695408</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.480275</td>\n",
       "      <td>0.319307</td>\n",
       "      <td>4.496841</td>\n",
       "      <td>0.170986</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.665816</td>\n",
       "      <td>0.676871</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>0.669218</td>\n",
       "      <td>0.674150</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.943227</td>\n",
       "      <td>4.006421</td>\n",
       "      <td>3.071111</td>\n",
       "      <td>0.224241</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.651361</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.621599</td>\n",
       "      <td>0.643707</td>\n",
       "      <td>0.628401</td>\n",
       "      <td>0.634184</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.324641</td>\n",
       "      <td>0.397191</td>\n",
       "      <td>4.291165</td>\n",
       "      <td>0.102518</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.695578</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>0.698980</td>\n",
       "      <td>0.699830</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.098225</td>\n",
       "      <td>0.767679</td>\n",
       "      <td>4.077977</td>\n",
       "      <td>0.116028</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'kernel': 'poly'}</td>\n",
       "      <td>0.698980</td>\n",
       "      <td>0.701531</td>\n",
       "      <td>0.688776</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.691327</td>\n",
       "      <td>0.694898</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.405732</td>\n",
       "      <td>0.453057</td>\n",
       "      <td>3.527203</td>\n",
       "      <td>0.207801</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 10, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.624150</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.606293</td>\n",
       "      <td>0.617347</td>\n",
       "      <td>0.596088</td>\n",
       "      <td>0.606633</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      19.877298      0.402755         3.374521        0.407636       1   \n",
       "1      17.557154      0.286680         4.539178        0.157519       1   \n",
       "2      16.346417      0.287686         4.132863        0.193988       1   \n",
       "3      18.480275      0.319307         4.496841        0.170986       1   \n",
       "4      49.943227      4.006421         3.071111        0.224241      10   \n",
       "5      16.324641      0.397191         4.291165        0.102518      10   \n",
       "6      16.098225      0.767679         4.077977        0.116028      10   \n",
       "7      13.405732      0.453057         3.527203        0.207801      10   \n",
       "\n",
       "  param_kernel                          params  split0_test_score  \\\n",
       "0       linear    {'C': 1, 'kernel': 'linear'}           0.677721   \n",
       "1          rbf       {'C': 1, 'kernel': 'rbf'}           0.703231   \n",
       "2         poly      {'C': 1, 'kernel': 'poly'}           0.709184   \n",
       "3      sigmoid   {'C': 1, 'kernel': 'sigmoid'}           0.673469   \n",
       "4       linear   {'C': 10, 'kernel': 'linear'}           0.651361   \n",
       "5          rbf      {'C': 10, 'kernel': 'rbf'}           0.695578   \n",
       "6         poly     {'C': 10, 'kernel': 'poly'}           0.698980   \n",
       "7      sigmoid  {'C': 10, 'kernel': 'sigmoid'}           0.624150   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.643707           0.643707           0.657313           0.653061   \n",
       "1           0.671769           0.702381           0.697279           0.682823   \n",
       "2           0.679422           0.701531           0.698980           0.687925   \n",
       "3           0.665816           0.676871           0.685374           0.669218   \n",
       "4           0.625850           0.621599           0.643707           0.628401   \n",
       "5           0.696429           0.685374           0.698980           0.699830   \n",
       "6           0.701531           0.688776           0.693878           0.691327   \n",
       "7           0.589286           0.606293           0.617347           0.596088   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.655102        0.012493                6  \n",
       "1         0.691497        0.012280                4  \n",
       "2         0.695408        0.010503                1  \n",
       "3         0.674150        0.006747                5  \n",
       "4         0.634184        0.011376                7  \n",
       "5         0.695238        0.005175                2  \n",
       "6         0.694898        0.004731                3  \n",
       "7         0.606633        0.012914                8  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid is doing the worst\n",
    "- Linear betwee 0.91 and 0.92\n",
    "- rbf: 0.93, 0.94\n",
    "- Poly: 0.94 (may be overfitting) but ar the best scores\n",
    "- Sigmoid, 0.93, 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC: \n",
    "Choose the best kernel and optimize that one.\n",
    "We have vectors in a many dimensional space, so we don't really know what is the valid choice. We just try to optimize the problem, not trying to explain what happens under the hood. \n",
    "\n",
    "## Radial Kernel - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 15s, sys: 1.62 s, total: 9min 17s\n",
      "Wall time: 9min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.5, 1, 5, 10, 20], 'kernel': ['rbf']})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':(['rbf']), 'C':[0.5, 1, 5, 10,20]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train_set, y_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'C': 1, 'kernel': 'linear'}, 0.9285714285714285),\n",
       " ({'C': 1, 'kernel': 'rbf'}, 0.9396258503401361),\n",
       " ({'C': 1, 'kernel': 'poly'}, 0.9430272108843537),\n",
       " ({'C': 1, 'kernel': 'sigmoid'}, 0.9333333333333333),\n",
       " ({'C': 10, 'kernel': 'linear'}, 0.9171768707482993),\n",
       " ({'C': 10, 'kernel': 'rbf'}, 0.9430272108843537),\n",
       " ({'C': 10, 'kernel': 'poly'}, 0.94421768707483),\n",
       " ({'C': 10, 'kernel': 'sigmoid'}, 0.9047619047619048)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(clf.cv_results_['params'], clf.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For 3 genres: Best value for RBF: {'C': 5, 'kernel': 'rbf'} 0.94\n",
    "- For 4 genres: ({'C': 5, 'kernel': 'rbf'}, 0.7687074829931972),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel\n",
    "Optimize _C_ value and degrees of the polynomial approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 44s, sys: 1.8 s, total: 6min 46s\n",
      "Wall time: 6min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.5, 1, 5, 10, 20], 'degree': [2, 3, 4],\n",
       "                         'kernel': ['poly']})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'kernel':(['poly']), 'C':[0.5, 1, 5, 10,20], 'degree':[2,3,4]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train_set, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'degree': 4, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.745979</td>\n",
       "      <td>0.055409</td>\n",
       "      <td>1.436245</td>\n",
       "      <td>0.015884</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.941327</td>\n",
       "      <td>0.937925</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>0.926020</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.645759</td>\n",
       "      <td>0.034395</td>\n",
       "      <td>1.396418</td>\n",
       "      <td>0.010783</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.937925</td>\n",
       "      <td>0.926020</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.938265</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.715809</td>\n",
       "      <td>0.077743</td>\n",
       "      <td>1.412590</td>\n",
       "      <td>0.020062</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.5, 'degree': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.937925</td>\n",
       "      <td>0.929422</td>\n",
       "      <td>0.950680</td>\n",
       "      <td>0.938946</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.152552</td>\n",
       "      <td>0.064650</td>\n",
       "      <td>1.227479</td>\n",
       "      <td>0.037168</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.944728</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.927721</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.940136</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.157955</td>\n",
       "      <td>0.080079</td>\n",
       "      <td>1.234929</td>\n",
       "      <td>0.037848</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.942177</td>\n",
       "      <td>0.932823</td>\n",
       "      <td>0.949830</td>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.287799</td>\n",
       "      <td>0.078636</td>\n",
       "      <td>1.266656</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'degree': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.953231</td>\n",
       "      <td>0.944728</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.611723</td>\n",
       "      <td>0.021955</td>\n",
       "      <td>1.027986</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 5, 'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.947279</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.930272</td>\n",
       "      <td>0.947279</td>\n",
       "      <td>0.941837</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.823354</td>\n",
       "      <td>0.063456</td>\n",
       "      <td>1.103924</td>\n",
       "      <td>0.033731</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 5, 'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.942177</td>\n",
       "      <td>0.932823</td>\n",
       "      <td>0.949830</td>\n",
       "      <td>0.943707</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.068640</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>1.197467</td>\n",
       "      <td>0.033810</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 5, 'degree': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.949830</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.614970</td>\n",
       "      <td>0.191798</td>\n",
       "      <td>1.060812</td>\n",
       "      <td>0.018255</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.949830</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.942177</td>\n",
       "      <td>0.942687</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.860320</td>\n",
       "      <td>0.082267</td>\n",
       "      <td>1.108493</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.950680</td>\n",
       "      <td>0.939626</td>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.944218</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.393415</td>\n",
       "      <td>0.306688</td>\n",
       "      <td>1.346382</td>\n",
       "      <td>0.092661</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'degree': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>0.947279</td>\n",
       "      <td>0.943707</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.674145</td>\n",
       "      <td>0.060214</td>\n",
       "      <td>1.014218</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 20, 'degree': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.947279</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>0.929422</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.941497</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.981502</td>\n",
       "      <td>0.090024</td>\n",
       "      <td>1.154943</td>\n",
       "      <td>0.045506</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 20, 'degree': 3, 'kernel': 'poly'}</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>0.932823</td>\n",
       "      <td>0.943027</td>\n",
       "      <td>0.941156</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.215285</td>\n",
       "      <td>0.099599</td>\n",
       "      <td>1.263416</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 20, 'degree': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.944728</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.939966</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        4.745979      0.055409         1.436245        0.015884     0.5   \n",
       "1        4.645759      0.034395         1.396418        0.010783     0.5   \n",
       "2        4.715809      0.077743         1.412590        0.020062     0.5   \n",
       "3        4.152552      0.064650         1.227479        0.037168       1   \n",
       "4        4.157955      0.080079         1.234929        0.037848       1   \n",
       "5        4.287799      0.078636         1.266656        0.031609       1   \n",
       "6        3.611723      0.021955         1.027986        0.020077       5   \n",
       "7        3.823354      0.063456         1.103924        0.033731       5   \n",
       "8        4.068640      0.061540         1.197467        0.033810       5   \n",
       "9        3.614970      0.191798         1.060812        0.018255      10   \n",
       "10       3.860320      0.082267         1.108493        0.036495      10   \n",
       "11       4.393415      0.306688         1.346382        0.092661      10   \n",
       "12       3.674145      0.060214         1.014218        0.032029      20   \n",
       "13       3.981502      0.090024         1.154943        0.045506      20   \n",
       "14       4.215285      0.099599         1.263416        0.041322      20   \n",
       "\n",
       "   param_degree param_kernel                                     params  \\\n",
       "0             2         poly  {'C': 0.5, 'degree': 2, 'kernel': 'poly'}   \n",
       "1             3         poly  {'C': 0.5, 'degree': 3, 'kernel': 'poly'}   \n",
       "2             4         poly  {'C': 0.5, 'degree': 4, 'kernel': 'poly'}   \n",
       "3             2         poly    {'C': 1, 'degree': 2, 'kernel': 'poly'}   \n",
       "4             3         poly    {'C': 1, 'degree': 3, 'kernel': 'poly'}   \n",
       "5             4         poly    {'C': 1, 'degree': 4, 'kernel': 'poly'}   \n",
       "6             2         poly    {'C': 5, 'degree': 2, 'kernel': 'poly'}   \n",
       "7             3         poly    {'C': 5, 'degree': 3, 'kernel': 'poly'}   \n",
       "8             4         poly    {'C': 5, 'degree': 4, 'kernel': 'poly'}   \n",
       "9             2         poly   {'C': 10, 'degree': 2, 'kernel': 'poly'}   \n",
       "10            3         poly   {'C': 10, 'degree': 3, 'kernel': 'poly'}   \n",
       "11            4         poly   {'C': 10, 'degree': 4, 'kernel': 'poly'}   \n",
       "12            2         poly   {'C': 20, 'degree': 2, 'kernel': 'poly'}   \n",
       "13            3         poly   {'C': 20, 'degree': 3, 'kernel': 'poly'}   \n",
       "14            4         poly   {'C': 20, 'degree': 4, 'kernel': 'poly'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.941327           0.937925           0.937075   \n",
       "1            0.938776           0.940476           0.937925   \n",
       "2            0.936224           0.940476           0.937925   \n",
       "3            0.938776           0.944728           0.940476   \n",
       "4            0.943878           0.946429           0.942177   \n",
       "5            0.943878           0.948129           0.943878   \n",
       "6            0.943878           0.947279           0.940476   \n",
       "7            0.948129           0.945578           0.942177   \n",
       "8            0.949830           0.948129           0.943027   \n",
       "9            0.949830           0.948980           0.940476   \n",
       "10           0.948980           0.950680           0.939626   \n",
       "11           0.948129           0.948980           0.937075   \n",
       "12           0.947279           0.948129           0.937075   \n",
       "13           0.946429           0.946429           0.937075   \n",
       "14           0.944728           0.943878           0.936224   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.926020           0.948129         0.938095        0.007183   \n",
       "1            0.926020           0.948129         0.938265        0.007106   \n",
       "2            0.929422           0.950680         0.938946        0.006917   \n",
       "3            0.927721           0.948980         0.940136        0.007147   \n",
       "4            0.932823           0.949830         0.943027        0.005717   \n",
       "5            0.934524           0.953231         0.944728        0.006155   \n",
       "6            0.930272           0.947279         0.941837        0.006309   \n",
       "7            0.932823           0.949830         0.943707        0.006022   \n",
       "8            0.936224           0.948980         0.945238        0.005091   \n",
       "9            0.931973           0.942177         0.942687        0.006489   \n",
       "10           0.933673           0.948129         0.944218        0.006512   \n",
       "11           0.937075           0.947279         0.943707        0.005442   \n",
       "12           0.929422           0.945578         0.941497        0.007203   \n",
       "13           0.932823           0.943027         0.941156        0.005389   \n",
       "14           0.934524           0.940476         0.939966        0.004046   \n",
       "\n",
       "    rank_test_score  \n",
       "0                15  \n",
       "1                14  \n",
       "2                13  \n",
       "3                11  \n",
       "4                 6  \n",
       "5                 2  \n",
       "6                 8  \n",
       "7                 4  \n",
       "8                 1  \n",
       "9                 7  \n",
       "10                3  \n",
       "11                4  \n",
       "12                9  \n",
       "13               10  \n",
       "14               12  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of calculations, but the differences are very small. So the poly nomial with 2 degrees and C=5 will do just fine. Better to have less degrees, than more to prevent overfitting.\n",
    "\n",
    "For 4 categories:\n",
    "- {'C': 1, 'degree': 3, 'kernel': 'poly'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# y_train_num = le.fit_transform(y_train_set)\n",
    "# y_val_num = le.transform(y_val_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier())])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "\n",
    "clf.fit(X_train_set, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6484126984126984"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance here is worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888095238095238"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train_set, y_train_set)\n",
    "\n",
    "predictions = neigh.predict(X_val_set)\n",
    "accuracy_score(y_val_set, predictions)\n",
    "# print(neigh.predict_proba([[0.9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this one in less accurate. But let's see if we can improve the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 5s, sys: 1.05 s, total: 3min 6s\n",
      "Wall time: 3min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(n_neighbors=3),\n",
       "             param_grid={'n_neighbors': [3, 4, 5, 6, 7]})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "parameters = {'n_neighbors':[3,4,5,6,7]}\n",
    "clf = GridSearchCV(neigh, parameters)\n",
    "clf.fit(X_train_set, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208835</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>7.194835</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.897109</td>\n",
       "      <td>0.914116</td>\n",
       "      <td>0.893707</td>\n",
       "      <td>0.909014</td>\n",
       "      <td>0.905102</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202581</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>7.242447</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.903912</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.900510</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221947</td>\n",
       "      <td>0.028751</td>\n",
       "      <td>7.263931</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.912415</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.920918</td>\n",
       "      <td>0.912245</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.203689</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>7.293332</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.893707</td>\n",
       "      <td>0.903912</td>\n",
       "      <td>0.894558</td>\n",
       "      <td>0.917517</td>\n",
       "      <td>0.904252</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.202390</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>7.298517</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.917517</td>\n",
       "      <td>0.903061</td>\n",
       "      <td>0.907313</td>\n",
       "      <td>0.905612</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.911735</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.208835      0.006383         7.194835        0.013695   \n",
       "1       0.202581      0.002646         7.242447        0.019047   \n",
       "2       0.221947      0.028751         7.263931        0.022776   \n",
       "3       0.203689      0.003995         7.293332        0.010813   \n",
       "4       0.202390      0.004232         7.298517        0.043988   \n",
       "\n",
       "  param_n_neighbors              params  split0_test_score  split1_test_score  \\\n",
       "0                 3  {'n_neighbors': 3}           0.911565           0.897109   \n",
       "1                 4  {'n_neighbors': 4}           0.903912           0.880952   \n",
       "2                 5  {'n_neighbors': 5}           0.925170           0.904762   \n",
       "3                 6  {'n_neighbors': 6}           0.911565           0.893707   \n",
       "4                 7  {'n_neighbors': 7}           0.917517           0.903061   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0           0.914116           0.893707           0.909014         0.905102   \n",
       "1           0.900510           0.887755           0.891156         0.892857   \n",
       "2           0.912415           0.897959           0.920918         0.912245   \n",
       "3           0.903912           0.894558           0.917517         0.904252   \n",
       "4           0.907313           0.905612           0.925170         0.911735   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.008149                3  \n",
       "1        0.008384                5  \n",
       "2        0.010024                1  \n",
       "3        0.009324                4  \n",
       "4        0.008321                2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8952380952380953"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=clf.best_params_[\"n_neighbors\"])\n",
    "neigh.fit(X_train_set, y_train_set)\n",
    "\n",
    "predictions = neigh.predict(X_val_set)\n",
    "accuracy_score(y_val_set, predictions)\n",
    "# print(neigh.predict_proba([[0.9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A little improvement over the 3 neighbors, but not so much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087301587301587"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train_set, y_train_set)\n",
    "\n",
    "predictions = clf.predict(X_val_set)\n",
    "accuracy_score(y_val_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this option also performs less. The assumption for Guassian distribution is probably als not valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = MLPClassifier(random_state=1, hidden_layer_sizes=(500,500), max_iter=500).fit(X_train_set, y_train_set)\n",
    "\n",
    "predictions = clf.predict(X_val_set)\n",
    "accuracy_score(y_val_set, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06823831e-18, 1.00000000e+00, 4.39361605e-23],\n",
       "       [1.00000000e+00, 5.75843456e-16, 1.89994343e-15],\n",
       "       [8.51008301e-06, 3.02647639e-08, 9.99991460e-01],\n",
       "       [8.09631690e-20, 1.00000000e+00, 2.84926628e-15],\n",
       "       [2.19418652e-11, 7.23780273e-13, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.21130592e-12, 1.50231330e-10],\n",
       "       [5.89613746e-08, 2.35962731e-09, 9.99999939e-01],\n",
       "       [1.00000000e+00, 2.32063741e-16, 1.82761602e-15],\n",
       "       [9.74750658e-01, 2.44990193e-08, 2.52493172e-02],\n",
       "       [2.53563641e-09, 1.10371443e-11, 9.99999997e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_val_set[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_val_set)\n",
    "accuracy_score(y_val_set, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val_set, y_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Hip Hop  Metal  Rock\n",
      "Hip Hop      762      0    78\n",
      "Metal          1    839     0\n",
      "Rock          58      3   779\n"
     ]
    }
   ],
   "source": [
    "# All the results are in the range of 92%-94%\n",
    "print_confustion_matrix(clf, y_val_set, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- different classifier have marginal effect\n",
    "- There must be something in the dataset in the Metal, it's classified correctly almost too much compared to the other genres. But is not clear what its. \n",
    "    - Some different languages. \n",
    "\n",
    "Best model: RBC for SVC\n",
    "({'C': 5, 'kernel': 'rbf'}, 0.7687074829931972) for 4 category classifier.\n",
    "\n",
    "Neural net: 500x500 hidden layers.\n",
    " - Pop and rock are the genres most closely related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the front end we'll set up the system with SVC, Radial kernel, with C=5\n",
    "- We fit the model on the complete training set\n",
    "- We evaluatoin on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19167</th>\n",
       "      <td>Back To Sleep</td>\n",
       "      <td>I know it's late, I know it's late. And baby I...</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>-0.273682</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>-0.246460</td>\n",
       "      <td>-0.050476</td>\n",
       "      <td>-0.072327</td>\n",
       "      <td>0.447510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408203</td>\n",
       "      <td>-1.025391</td>\n",
       "      <td>-0.107178</td>\n",
       "      <td>-0.021561</td>\n",
       "      <td>0.352051</td>\n",
       "      <td>0.488770</td>\n",
       "      <td>-0.528320</td>\n",
       "      <td>-0.062469</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.423340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88089</th>\n",
       "      <td>The Best</td>\n",
       "      <td>The Best. Soulja Boy. Soulja! Soulja! Soulja! ...</td>\n",
       "      <td>Soulja Boy</td>\n",
       "      <td>0.037231</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>0.496826</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>-0.322998</td>\n",
       "      <td>-0.077271</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>-0.338623</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.612305</td>\n",
       "      <td>0.417236</td>\n",
       "      <td>-0.303955</td>\n",
       "      <td>-0.520508</td>\n",
       "      <td>0.493164</td>\n",
       "      <td>0.340820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41285</th>\n",
       "      <td>Just Askin'</td>\n",
       "      <td>Wassup, in your world?. And are you still cool...</td>\n",
       "      <td>Iggy Azalea</td>\n",
       "      <td>-0.041718</td>\n",
       "      <td>-0.246704</td>\n",
       "      <td>-0.162720</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>-0.043579</td>\n",
       "      <td>-0.229004</td>\n",
       "      <td>0.499023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738770</td>\n",
       "      <td>-0.558594</td>\n",
       "      <td>-0.090698</td>\n",
       "      <td>-0.180176</td>\n",
       "      <td>0.313232</td>\n",
       "      <td>0.296143</td>\n",
       "      <td>-0.604004</td>\n",
       "      <td>-0.382080</td>\n",
       "      <td>0.578613</td>\n",
       "      <td>0.207520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12664</th>\n",
       "      <td>You Wear A Crown But You're No King</td>\n",
       "      <td>You'll never stop 'til you get what you want. ...</td>\n",
       "      <td>Blessthefall</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.143311</td>\n",
       "      <td>-0.226196</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.749023</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>0.955078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>-0.275879</td>\n",
       "      <td>-0.046143</td>\n",
       "      <td>-0.173706</td>\n",
       "      <td>0.242676</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>-0.583008</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.259033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52249</th>\n",
       "      <td>Kevin Gates</td>\n",
       "      <td>Workout. Tell. Workout. Tell. Gates. Gates. Ga...</td>\n",
       "      <td>Kevin Gates</td>\n",
       "      <td>0.061066</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.814453</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>-0.344238</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408936</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>-0.401855</td>\n",
       "      <td>0.095398</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.496582</td>\n",
       "      <td>-0.437256</td>\n",
       "      <td>0.364258</td>\n",
       "      <td>0.228882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     SName  \\\n",
       "19167                        Back To Sleep   \n",
       "88089                             The Best   \n",
       "41285                          Just Askin'   \n",
       "12664  You Wear A Crown But You're No King   \n",
       "52249                          Kevin Gates   \n",
       "\n",
       "                                                   Lyric        Artist  \\\n",
       "19167  I know it's late, I know it's late. And baby I...   Chris Brown   \n",
       "88089  The Best. Soulja Boy. Soulja! Soulja! Soulja! ...    Soulja Boy   \n",
       "41285  Wassup, in your world?. And are you still cool...   Iggy Azalea   \n",
       "12664  You'll never stop 'til you get what you want. ...  Blessthefall   \n",
       "52249  Workout. Tell. Workout. Tell. Gates. Gates. Ga...   Kevin Gates   \n",
       "\n",
       "              0         1         2         3         4         5         6  \\\n",
       "19167  0.001492 -0.273682  0.150513 -0.246460 -0.050476 -0.072327  0.447510   \n",
       "88089  0.037231  0.150635  0.496826  0.196777 -0.322998 -0.077271  0.991211   \n",
       "41285 -0.041718 -0.246704 -0.162720  0.137085 -0.043579 -0.229004  0.499023   \n",
       "12664 -0.325684  0.143311 -0.226196 -0.002642 -0.749023  0.127930  0.955078   \n",
       "52249  0.061066  0.076416  0.814453 -0.269531 -0.344238  0.150757  0.812500   \n",
       "\n",
       "       ...       758       759       760       761       762       763  \\\n",
       "19167  ...  0.408203 -1.025391 -0.107178 -0.021561  0.352051  0.488770   \n",
       "88089  ...  0.160156 -0.338623  0.003363  0.037933  0.612305  0.417236   \n",
       "41285  ...  0.738770 -0.558594 -0.090698 -0.180176  0.313232  0.296143   \n",
       "12664  ...  0.154175 -0.275879 -0.046143 -0.173706  0.242676  0.716797   \n",
       "52249  ... -0.408936 -0.527344 -0.401855  0.095398  0.742676  0.281250   \n",
       "\n",
       "            764       765       766       767  \n",
       "19167 -0.528320 -0.062469  0.002211  0.423340  \n",
       "88089 -0.303955 -0.520508  0.493164  0.340820  \n",
       "41285 -0.604004 -0.382080  0.578613  0.207520  \n",
       "12664 -0.252197 -0.583008  0.321533  0.259033  \n",
       "52249 -0.496582 -0.437256  0.364258  0.228882  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19167     Hip Hop\n",
       "88089     Hip Hop\n",
       "41285     Hip Hop\n",
       "12664        Rock\n",
       "52249     Hip Hop\n",
       "           ...   \n",
       "127879      Metal\n",
       "80491        Rock\n",
       "66750        Rock\n",
       "133337      Metal\n",
       "99994        Rock\n",
       "Name: Genre, Length: 8400, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19167</th>\n",
       "      <td>0.001492</td>\n",
       "      <td>-0.273682</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>-0.246460</td>\n",
       "      <td>-0.050476</td>\n",
       "      <td>-0.072327</td>\n",
       "      <td>0.447510</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>-0.255859</td>\n",
       "      <td>-0.431396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408203</td>\n",
       "      <td>-1.025391</td>\n",
       "      <td>-0.107178</td>\n",
       "      <td>-0.021561</td>\n",
       "      <td>0.352051</td>\n",
       "      <td>0.488770</td>\n",
       "      <td>-0.528320</td>\n",
       "      <td>-0.062469</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.423340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88089</th>\n",
       "      <td>0.037231</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>0.496826</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>-0.322998</td>\n",
       "      <td>-0.077271</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>-0.482910</td>\n",
       "      <td>-0.359619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>-0.338623</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.612305</td>\n",
       "      <td>0.417236</td>\n",
       "      <td>-0.303955</td>\n",
       "      <td>-0.520508</td>\n",
       "      <td>0.493164</td>\n",
       "      <td>0.340820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41285</th>\n",
       "      <td>-0.041718</td>\n",
       "      <td>-0.246704</td>\n",
       "      <td>-0.162720</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>-0.043579</td>\n",
       "      <td>-0.229004</td>\n",
       "      <td>0.499023</td>\n",
       "      <td>0.824219</td>\n",
       "      <td>0.036102</td>\n",
       "      <td>-0.441650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738770</td>\n",
       "      <td>-0.558594</td>\n",
       "      <td>-0.090698</td>\n",
       "      <td>-0.180176</td>\n",
       "      <td>0.313232</td>\n",
       "      <td>0.296143</td>\n",
       "      <td>-0.604004</td>\n",
       "      <td>-0.382080</td>\n",
       "      <td>0.578613</td>\n",
       "      <td>0.207520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12664</th>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.143311</td>\n",
       "      <td>-0.226196</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.749023</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>0.955078</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>-0.119263</td>\n",
       "      <td>-0.517090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>-0.275879</td>\n",
       "      <td>-0.046143</td>\n",
       "      <td>-0.173706</td>\n",
       "      <td>0.242676</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>-0.583008</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.259033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52249</th>\n",
       "      <td>0.061066</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.814453</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>-0.344238</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.367432</td>\n",
       "      <td>-0.025284</td>\n",
       "      <td>-0.302490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408936</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>-0.401855</td>\n",
       "      <td>0.095398</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.496582</td>\n",
       "      <td>-0.437256</td>\n",
       "      <td>0.364258</td>\n",
       "      <td>0.228882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127879</th>\n",
       "      <td>-0.169678</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>-0.042542</td>\n",
       "      <td>-0.390625</td>\n",
       "      <td>-0.249268</td>\n",
       "      <td>0.797852</td>\n",
       "      <td>0.419189</td>\n",
       "      <td>-0.269531</td>\n",
       "      <td>-0.881348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206543</td>\n",
       "      <td>-0.823730</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>-0.105835</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.190796</td>\n",
       "      <td>-0.207031</td>\n",
       "      <td>-0.497314</td>\n",
       "      <td>0.233032</td>\n",
       "      <td>-0.636230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80491</th>\n",
       "      <td>-0.017868</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.343506</td>\n",
       "      <td>-0.726562</td>\n",
       "      <td>-0.599609</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.419678</td>\n",
       "      <td>0.360107</td>\n",
       "      <td>0.517578</td>\n",
       "      <td>-0.833008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453857</td>\n",
       "      <td>-0.279053</td>\n",
       "      <td>-0.021866</td>\n",
       "      <td>-0.483154</td>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.191284</td>\n",
       "      <td>-0.330811</td>\n",
       "      <td>-0.092896</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>0.769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66750</th>\n",
       "      <td>-0.179810</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>-0.214478</td>\n",
       "      <td>0.788574</td>\n",
       "      <td>0.704102</td>\n",
       "      <td>-0.184082</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.797852</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>-0.049011</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.599609</td>\n",
       "      <td>-0.137939</td>\n",
       "      <td>-0.099487</td>\n",
       "      <td>-0.040466</td>\n",
       "      <td>0.257568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133337</th>\n",
       "      <td>-0.553223</td>\n",
       "      <td>0.139282</td>\n",
       "      <td>0.312256</td>\n",
       "      <td>0.208862</td>\n",
       "      <td>-0.581055</td>\n",
       "      <td>-0.247070</td>\n",
       "      <td>0.706543</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.349121</td>\n",
       "      <td>-0.726074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300049</td>\n",
       "      <td>-0.753906</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>-0.461670</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>-0.375977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>-0.023071</td>\n",
       "      <td>0.130493</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.077026</td>\n",
       "      <td>-0.200073</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.388184</td>\n",
       "      <td>0.555176</td>\n",
       "      <td>-0.610840</td>\n",
       "      <td>-0.278076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139771</td>\n",
       "      <td>-0.655762</td>\n",
       "      <td>-0.319092</td>\n",
       "      <td>-0.176147</td>\n",
       "      <td>0.576660</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>-0.161743</td>\n",
       "      <td>-0.162109</td>\n",
       "      <td>0.387939</td>\n",
       "      <td>0.464111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "19167   0.001492 -0.273682  0.150513 -0.246460 -0.050476 -0.072327  0.447510   \n",
       "88089   0.037231  0.150635  0.496826  0.196777 -0.322998 -0.077271  0.991211   \n",
       "41285  -0.041718 -0.246704 -0.162720  0.137085 -0.043579 -0.229004  0.499023   \n",
       "12664  -0.325684  0.143311 -0.226196 -0.002642 -0.749023  0.127930  0.955078   \n",
       "52249   0.061066  0.076416  0.814453 -0.269531 -0.344238  0.150757  0.812500   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "127879 -0.169678  0.041229  0.236816 -0.042542 -0.390625 -0.249268  0.797852   \n",
       "80491  -0.017868  0.076111  0.343506 -0.726562 -0.599609  0.000035  0.419678   \n",
       "66750  -0.179810 -0.208984 -0.071289  0.151611 -0.094727 -0.214478  0.788574   \n",
       "133337 -0.553223  0.139282  0.312256  0.208862 -0.581055 -0.247070  0.706543   \n",
       "99994  -0.023071  0.130493  0.133423  0.077026 -0.200073  0.148804  0.388184   \n",
       "\n",
       "             7         8         9    ...       758       759       760  \\\n",
       "19167   0.275391 -0.255859 -0.431396  ...  0.408203 -1.025391 -0.107178   \n",
       "88089   0.152954 -0.482910 -0.359619  ...  0.160156 -0.338623  0.003363   \n",
       "41285   0.824219  0.036102 -0.441650  ...  0.738770 -0.558594 -0.090698   \n",
       "12664   0.399902 -0.119263 -0.517090  ...  0.154175 -0.275879 -0.046143   \n",
       "52249   0.367432 -0.025284 -0.302490  ... -0.408936 -0.527344 -0.401855   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "127879  0.419189 -0.269531 -0.881348  ... -0.206543 -0.823730 -0.051056   \n",
       "80491   0.360107  0.517578 -0.833008  ...  0.453857 -0.279053 -0.021866   \n",
       "66750   0.704102 -0.184082 -0.365723  ...  0.017578 -0.797852  0.142456   \n",
       "133337  0.520508  0.349121 -0.726074  ... -0.300049 -0.753906 -0.207153   \n",
       "99994   0.555176 -0.610840 -0.278076  ...  0.139771 -0.655762 -0.319092   \n",
       "\n",
       "             761       762       763       764       765       766       767  \n",
       "19167  -0.021561  0.352051  0.488770 -0.528320 -0.062469  0.002211  0.423340  \n",
       "88089   0.037933  0.612305  0.417236 -0.303955 -0.520508  0.493164  0.340820  \n",
       "41285  -0.180176  0.313232  0.296143 -0.604004 -0.382080  0.578613  0.207520  \n",
       "12664  -0.173706  0.242676  0.716797 -0.252197 -0.583008  0.321533  0.259033  \n",
       "52249   0.095398  0.742676  0.281250 -0.496582 -0.437256  0.364258  0.228882  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "127879 -0.105835  0.450439  0.190796 -0.207031 -0.497314  0.233032 -0.636230  \n",
       "80491  -0.483154  0.136719  0.191284 -0.330811 -0.092896  0.070190  0.769043  \n",
       "66750  -0.049011  0.182617  0.599609 -0.137939 -0.099487 -0.040466  0.257568  \n",
       "133337 -0.024521  0.374512  0.519043  0.003078 -0.461670  0.013908 -0.375977  \n",
       "99994  -0.176147  0.576660  0.502441 -0.161743 -0.162109  0.387939  0.464111  \n",
       "\n",
       "[8400 rows x 768 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final = X_train.drop(text_cols, axis=1)\n",
    "X_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(max_iter=4000, kernel='rbf', C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, max_iter=4000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, gzip.open(f'{path}{\"final_lyrics_model.pkl.gz\"}', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 771) (3600,)\n"
     ]
    }
   ],
   "source": [
    "# load the test set\n",
    "X_test = pd.read_pickle(f'{path}X_test.pkl.gz')\n",
    "y_test = pd.read_pickle(f'{path}y_test.pkl.gz')\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89956</th>\n",
       "      <td>-0.244995</td>\n",
       "      <td>-0.127075</td>\n",
       "      <td>0.097412</td>\n",
       "      <td>-0.187256</td>\n",
       "      <td>-0.259521</td>\n",
       "      <td>-0.194092</td>\n",
       "      <td>0.568359</td>\n",
       "      <td>0.562012</td>\n",
       "      <td>-0.143677</td>\n",
       "      <td>-0.538086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>-0.501465</td>\n",
       "      <td>-0.123047</td>\n",
       "      <td>-0.450195</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.800293</td>\n",
       "      <td>-0.675293</td>\n",
       "      <td>0.069397</td>\n",
       "      <td>0.398193</td>\n",
       "      <td>0.586426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33634</th>\n",
       "      <td>-0.034454</td>\n",
       "      <td>-0.149658</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>-0.213867</td>\n",
       "      <td>-0.482178</td>\n",
       "      <td>-0.253418</td>\n",
       "      <td>0.167114</td>\n",
       "      <td>0.550293</td>\n",
       "      <td>-0.196533</td>\n",
       "      <td>-0.573242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312744</td>\n",
       "      <td>-0.751465</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>-0.265137</td>\n",
       "      <td>-0.074219</td>\n",
       "      <td>0.669434</td>\n",
       "      <td>-0.548828</td>\n",
       "      <td>-0.318848</td>\n",
       "      <td>0.070435</td>\n",
       "      <td>0.294678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16861</th>\n",
       "      <td>0.141235</td>\n",
       "      <td>-0.208374</td>\n",
       "      <td>0.282715</td>\n",
       "      <td>-0.068359</td>\n",
       "      <td>-0.137085</td>\n",
       "      <td>-0.065552</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>-0.515137</td>\n",
       "      <td>-0.383545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>-0.604492</td>\n",
       "      <td>-0.254639</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>0.430420</td>\n",
       "      <td>0.540527</td>\n",
       "      <td>-0.599121</td>\n",
       "      <td>-0.480957</td>\n",
       "      <td>0.131470</td>\n",
       "      <td>0.092529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92314</th>\n",
       "      <td>0.345215</td>\n",
       "      <td>0.182495</td>\n",
       "      <td>0.065552</td>\n",
       "      <td>-0.339355</td>\n",
       "      <td>-0.525391</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.584473</td>\n",
       "      <td>0.826660</td>\n",
       "      <td>-0.712402</td>\n",
       "      <td>-0.538574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051819</td>\n",
       "      <td>-0.761719</td>\n",
       "      <td>-0.501953</td>\n",
       "      <td>-0.466064</td>\n",
       "      <td>0.818848</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>-0.710449</td>\n",
       "      <td>-0.107666</td>\n",
       "      <td>0.366455</td>\n",
       "      <td>0.580566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95289</th>\n",
       "      <td>-0.081360</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.453613</td>\n",
       "      <td>-0.090454</td>\n",
       "      <td>-0.411133</td>\n",
       "      <td>0.203369</td>\n",
       "      <td>0.451904</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>-0.225098</td>\n",
       "      <td>-1.244141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079285</td>\n",
       "      <td>-0.294922</td>\n",
       "      <td>-0.215332</td>\n",
       "      <td>-0.411865</td>\n",
       "      <td>0.302002</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>-0.223267</td>\n",
       "      <td>-0.057770</td>\n",
       "      <td>0.276611</td>\n",
       "      <td>0.663574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118197</th>\n",
       "      <td>-0.474121</td>\n",
       "      <td>0.379395</td>\n",
       "      <td>-0.052002</td>\n",
       "      <td>0.240479</td>\n",
       "      <td>-0.168701</td>\n",
       "      <td>0.211792</td>\n",
       "      <td>0.625488</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>-0.714844</td>\n",
       "      <td>-0.219116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.462158</td>\n",
       "      <td>-0.062866</td>\n",
       "      <td>0.413330</td>\n",
       "      <td>0.089294</td>\n",
       "      <td>-0.097717</td>\n",
       "      <td>-0.487793</td>\n",
       "      <td>0.321045</td>\n",
       "      <td>0.369385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152448</th>\n",
       "      <td>-0.527832</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.091675</td>\n",
       "      <td>-0.161011</td>\n",
       "      <td>-0.460449</td>\n",
       "      <td>-0.021591</td>\n",
       "      <td>0.848633</td>\n",
       "      <td>0.563477</td>\n",
       "      <td>-0.372070</td>\n",
       "      <td>-0.105286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>-0.675781</td>\n",
       "      <td>-0.113892</td>\n",
       "      <td>0.237061</td>\n",
       "      <td>-0.147217</td>\n",
       "      <td>0.264648</td>\n",
       "      <td>-0.349609</td>\n",
       "      <td>-0.316895</td>\n",
       "      <td>0.336182</td>\n",
       "      <td>0.521973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66130</th>\n",
       "      <td>-0.265137</td>\n",
       "      <td>-0.281738</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>-0.453857</td>\n",
       "      <td>-0.122620</td>\n",
       "      <td>0.360352</td>\n",
       "      <td>0.526367</td>\n",
       "      <td>0.146240</td>\n",
       "      <td>-0.671875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164673</td>\n",
       "      <td>-0.479248</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>-0.120239</td>\n",
       "      <td>-0.066345</td>\n",
       "      <td>0.391846</td>\n",
       "      <td>-0.296387</td>\n",
       "      <td>-0.319336</td>\n",
       "      <td>0.227051</td>\n",
       "      <td>0.458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104573</th>\n",
       "      <td>-0.182373</td>\n",
       "      <td>-0.352783</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>-0.426514</td>\n",
       "      <td>-0.583984</td>\n",
       "      <td>0.259277</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.958008</td>\n",
       "      <td>-0.179932</td>\n",
       "      <td>-0.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082947</td>\n",
       "      <td>-0.488770</td>\n",
       "      <td>-0.828125</td>\n",
       "      <td>-0.507324</td>\n",
       "      <td>0.489746</td>\n",
       "      <td>0.223267</td>\n",
       "      <td>-0.271973</td>\n",
       "      <td>-0.354004</td>\n",
       "      <td>0.679199</td>\n",
       "      <td>0.349854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>0.114258</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>0.584473</td>\n",
       "      <td>-0.508301</td>\n",
       "      <td>-0.623535</td>\n",
       "      <td>-0.101624</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>-0.146118</td>\n",
       "      <td>-0.308838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078491</td>\n",
       "      <td>-0.495361</td>\n",
       "      <td>-0.151733</td>\n",
       "      <td>-0.294434</td>\n",
       "      <td>0.426025</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>-0.478027</td>\n",
       "      <td>-0.297119</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>0.459473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "89956  -0.244995 -0.127075  0.097412 -0.187256 -0.259521 -0.194092  0.568359   \n",
       "33634  -0.034454 -0.149658  0.664062 -0.213867 -0.482178 -0.253418  0.167114   \n",
       "16861   0.141235 -0.208374  0.282715 -0.068359 -0.137085 -0.065552  0.525391   \n",
       "92314   0.345215  0.182495  0.065552 -0.339355 -0.525391  0.010788  0.584473   \n",
       "95289  -0.081360  0.009384  0.453613 -0.090454 -0.411133  0.203369  0.451904   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "118197 -0.474121  0.379395 -0.052002  0.240479 -0.168701  0.211792  0.625488   \n",
       "152448 -0.527832  0.535156  0.091675 -0.161011 -0.460449 -0.021591  0.848633   \n",
       "66130  -0.265137 -0.281738  0.449219 -0.094727 -0.453857 -0.122620  0.360352   \n",
       "104573 -0.182373 -0.352783  0.146484 -0.426514 -0.583984  0.259277  0.880859   \n",
       "24343   0.114258 -0.140625  0.584473 -0.508301 -0.623535 -0.101624  0.746094   \n",
       "\n",
       "             7         8         9    ...       758       759       760  \\\n",
       "89956   0.562012 -0.143677 -0.538086  ...  0.078186 -0.501465 -0.123047   \n",
       "33634   0.550293 -0.196533 -0.573242  ... -0.312744 -0.751465  0.074219   \n",
       "16861   0.498535 -0.515137 -0.383545  ...  0.154785 -0.604492 -0.254639   \n",
       "92314   0.826660 -0.712402 -0.538574  ... -0.051819 -0.761719 -0.501953   \n",
       "95289   0.871094 -0.225098 -1.244141  ... -0.079285 -0.294922 -0.215332   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "118197  0.508789 -0.714844 -0.219116  ...  0.605469 -0.621094 -0.462158   \n",
       "152448  0.563477 -0.372070 -0.105286  ...  0.512207 -0.675781 -0.113892   \n",
       "66130   0.526367  0.146240 -0.671875  ... -0.164673 -0.479248  0.071411   \n",
       "104573  0.958008 -0.179932 -0.843750  ...  0.082947 -0.488770 -0.828125   \n",
       "24343   0.502441 -0.146118 -0.308838  ... -0.078491 -0.495361 -0.151733   \n",
       "\n",
       "             761       762       763       764       765       766       767  \n",
       "89956  -0.450195  0.400635  0.800293 -0.675293  0.069397  0.398193  0.586426  \n",
       "33634  -0.265137 -0.074219  0.669434 -0.548828 -0.318848  0.070435  0.294678  \n",
       "16861  -0.252930  0.430420  0.540527 -0.599121 -0.480957  0.131470  0.092529  \n",
       "92314  -0.466064  0.818848  0.695801 -0.710449 -0.107666  0.366455  0.580566  \n",
       "95289  -0.411865  0.302002  0.394043 -0.223267 -0.057770  0.276611  0.663574  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "118197 -0.062866  0.413330  0.089294 -0.097717 -0.487793  0.321045  0.369385  \n",
       "152448  0.237061 -0.147217  0.264648 -0.349609 -0.316895  0.336182  0.521973  \n",
       "66130  -0.120239 -0.066345  0.391846 -0.296387 -0.319336  0.227051  0.458984  \n",
       "104573 -0.507324  0.489746  0.223267 -0.271973 -0.354004  0.679199  0.349854  \n",
       "24343  -0.294434  0.426025  0.461182 -0.478027 -0.297119  0.523926  0.459473  \n",
       "\n",
       "[3600 rows x 768 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final = X_test.drop(text_cols, axis=1)\n",
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Accuracy: {round(acc,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Hip Hop  Metal  Rock\n",
      "Hip Hop     1063      0   137\n",
      "Metal          0   1200     0\n",
      "Rock          57      1  1142\n"
     ]
    }
   ],
   "source": [
    "print_confustion_matrix(model, y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hip Hop       0.95      0.89      0.92      1200\n",
      "        Rock       1.00      1.00      1.00      1200\n",
      "       Metal       0.89      0.95      0.92      1200\n",
      "\n",
      "    accuracy                           0.95      3600\n",
      "   macro avg       0.95      0.95      0.95      3600\n",
      "weighted avg       0.95      0.95      0.95      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_predictions, target_names=genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
